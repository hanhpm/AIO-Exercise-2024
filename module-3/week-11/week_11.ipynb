{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iboyw5_Fm8g6",
        "outputId": "04bd8cfe-1c02-4395-fda0-b51b83d34bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gini Impurity: 0.4800\n",
            "Entropy: 0.9710\n"
          ]
        }
      ],
      "source": [
        "# Câu 2 và câu 5\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Calculate Gini Impurity\n",
        "def gini_impurity(labels):\n",
        "    total_samples = len(labels)\n",
        "    # Get the unique labels and their frequencies\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / total_samples\n",
        "    # Calculate Gini Impurity\n",
        "    gini = 1 - np.sum(probabilities**2)\n",
        "    return gini\n",
        "\n",
        "# Calculate Entropy\n",
        "def entropy(labels):\n",
        "    total_samples = len(labels)\n",
        "    # Get the unique labels and their frequencies\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / total_samples\n",
        "    # Calculate Entropy\n",
        "    ent = -np.sum(probabilities * np.log2(probabilities))\n",
        "    return ent\n",
        "\n",
        "# Dataset\n",
        "labels = [1, 1, 0, 0, 0]\n",
        "\n",
        "gini = gini_impurity(labels)\n",
        "ent = entropy(labels)\n",
        "\n",
        "print(f\"Gini Impurity: {gini:.4f}\")\n",
        "print(f\"Entropy: {ent:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Câu 6\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Function to calculate entropy\n",
        "def entropy(labels):\n",
        "    total_samples = len(labels)\n",
        "    _, counts = np.unique(labels, return_counts=True)\n",
        "    probabilities = counts / total_samples\n",
        "    ent = -np.sum(probabilities * np.log2(probabilities))\n",
        "    return ent\n",
        "\n",
        "# Function to calculate weighted entropy after split\n",
        "def weighted_entropy(subsets, total_samples):\n",
        "    weighted_ent = 0\n",
        "    for subset in subsets:\n",
        "        weighted_ent += (len(subset) / total_samples) * entropy(subset)\n",
        "    return weighted_ent\n",
        "\n",
        "# Function to calculate Information Gain\n",
        "def information_gain(total_entropy, subsets, total_samples):\n",
        "    gain = total_entropy - weighted_entropy(subsets, total_samples)\n",
        "    return gain\n",
        "\n",
        "# Dataset\n",
        "# Age, Likes English, Likes AI, Raise Salary\n",
        "data = [\n",
        "    [23, 0, 0, 0],\n",
        "    [25, 1, 1, 0],\n",
        "    [27, 1, 0, 1],\n",
        "    [29, 0, 1, 1],\n",
        "    [29, 0, 0, 0]\n",
        "]\n",
        "\n",
        "# Extract the target variable (Raise Salary)\n",
        "raise_salary = [row[3] for row in data]\n",
        "\n",
        "# Calculate entropy of the entire dataset\n",
        "total_entropy = entropy(raise_salary)\n",
        "\n",
        "# Split based on 'Likes English'\n",
        "subset_0 = [row[3] for row in data if row[1] == 0]\n",
        "subset_1 = [row[3] for row in data if row[1] == 1]\n",
        "\n",
        "# Total number of samples\n",
        "total_samples = len(raise_salary)\n",
        "\n",
        "# Calculate Gain for 'Likes English'\n",
        "gain_likes_english = information_gain(total_entropy, [subset_0, subset_1], total_samples)\n",
        "\n",
        "# Output the result\n",
        "print(f\"Entropy of the entire dataset: {total_entropy:.4f}\")\n",
        "print(f\"Entropy of 'Likes English = 0' subset: {entropy(subset_0):.4f}\")\n",
        "print(f\"Entropy of 'Likes English = 1' subset: {entropy(subset_1):.4f}\")\n",
        "print(f\"Information Gain when splitting by 'Likes English': {gain_likes_english:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSOFPFK5wAnA",
        "outputId": "8ac5610a-190a-45c6-de45-fcc7f35f02cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entropy of the entire dataset: 0.9710\n",
            "Entropy of 'Likes English = 0' subset: 0.9183\n",
            "Entropy of 'Likes English = 1' subset: 1.0000\n",
            "Information Gain when splitting by 'Likes English': 0.0200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cau 9 - 10\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Given data\n",
        "ages = np.array([23, 25, 27, 29, 29])\n",
        "likes_english = np.array([0, 1, 1, 0, 0])\n",
        "likes_ai = np.array([0, 1, 0, 1, 0])\n",
        "salaries = np.array([200, 400, 300, 500, 400])\n",
        "\n",
        "# Calculate SSE\n",
        "def calculate_sse(data, mean):\n",
        "    return np.sum((data - mean) ** 2)\n",
        "\n",
        "# SSE when 'Likes AI' is the root node\n",
        "likes_ai_0 = salaries[likes_ai == 0]\n",
        "likes_ai_1 = salaries[likes_ai == 1]\n",
        "\n",
        "mean_likes_ai_0 = np.mean(likes_ai_0)\n",
        "mean_likes_ai_1 = np.mean(likes_ai_1)\n",
        "\n",
        "sse_likes_ai_0 = calculate_sse(likes_ai_0, mean_likes_ai_0)\n",
        "sse_likes_ai_1 = calculate_sse(likes_ai_1, mean_likes_ai_1)\n",
        "\n",
        "total_sse_likes_ai = sse_likes_ai_0 + sse_likes_ai_1\n",
        "print(f\"SSE when 'Likes AI' is the root node: {total_sse_likes_ai}\")\n",
        "\n",
        "# SSE when 'Age' is the root node with condition 'Age <= 24'\n",
        "age_24 = salaries[ages <= 24]\n",
        "age_above_24 = salaries[ages > 24]\n",
        "\n",
        "mean_age_24 = np.mean(age_24)\n",
        "mean_age_above_24 = np.mean(age_above_24)\n",
        "\n",
        "sse_age_24 = calculate_sse(age_24, mean_age_24)\n",
        "sse_age_above_24 = calculate_sse(age_above_24, mean_age_above_24)\n",
        "\n",
        "total_sse_age = sse_age_24 + sse_age_above_24\n",
        "print(f\"SSE when 'Age <= 24' is the root node: {total_sse_age}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcXt3jA4AKlJ",
        "outputId": "cdca39b1-ad10-43cd-a488-1d6292f7caa7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSE when 'Likes AI' is the root node: 25000.0\n",
            "SSE when 'Age <= 24' is the root node: 20000.0\n"
          ]
        }
      ]
    }
  ]
}