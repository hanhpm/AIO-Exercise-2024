{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QjC4fYj2rheE",
        "outputId": "437df207-a4c0-4ad2-d243-13c5baeb4596"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 8: !apt-get: command not found\n",
            "/bin/bash: line 9: !apt-get: command not found\n",
            "--2025-03-30 16:24:24--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 142.251.2.136, 142.251.2.93, 142.251.2.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|142.251.2.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 114483440 (109M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 109.18M   225MB/s    in 0.5s    \n",
            "\n",
            "2025-03-30 16:24:24 (225 MB/s) - ‘google-chrome-stable_current_amd64.deb’ saved [114483440/114483440]\n",
            "\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 29 not upgraded.\n",
            "Need to get 10.9 MB/125 MB of archives.\n",
            "After this operation, 425 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 134.0.6998.165-1 [114 MB]\n",
            "Fetched 10.9 MB in 2s (5,588 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 126209 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (134.0.6998.165-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (134.0.6998.165-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "Archive:  chromedriver_linux64.zip\n",
            "  inflating: chromedriver            \n",
            "  inflating: LICENSE.chromedriver    \n",
            "/bin/bash: line 23: !pip: command not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command '# Install chromium and chromium-driver using apt\n# apt-get update\n# apt-get install chromium chromium-driver # original code\n\n# Suggested Change: Install chromium using wget\n# Debian no longer provides chromium in Buster or Bullseye\n# Proposed solution: https://gist.github.com/korakot/f908ecc86f265ea290f5c6a9c7524031\n!apt-get update  # Update package lists to ensure apt can find the necessary packages\n!apt-get install -y wget curl unzip # Install wget, curl, and unzip if they are not already present\n\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\napt install ./google-chrome-stable_current_amd64.deb -y\n\n# Install chromedriver using wget\n# Proposed solution: https://stackoverflow.com/a/74827505\nCHROMEDRIVER_VERSION=$(curl -sS -o - https://chromedriver.storage.googleapis.com/LATEST_RELEASE)\nwget -q --continue https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip\nunzip chromedriver_linux64.zip\nchmod +x chromedriver\nmv chromedriver /usr/bin/chromedriver\n\n# Install Selenium\n!pip install selenium\n' returned non-zero exit status 127.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-63d4f8c4acb3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'shell'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# Install chromium and chromium-driver using apt\\n# apt-get update\\n# apt-get install chromium chromium-driver # original code\\n\\n# Suggested Change: Install chromium using wget\\n# Debian no longer provides chromium in Buster or Bullseye\\n# Proposed solution: https://gist.github.com/korakot/f908ecc86f265ea290f5c6a9c7524031\\n!apt-get update  # Update package lists to ensure apt can find the necessary packages\\n!apt-get install -y wget curl unzip # Install wget, curl, and unzip if they are not already present\\n\\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\\napt install ./google-chrome-stable_current_amd64.deb -y\\n\\n# Install chromedriver using wget\\n# Proposed solution: https://stackoverflow.com/a/74827505\\nCHROMEDRIVER_VERSION=$(curl -sS -o - https://chromedriver.storage.googleapis.com/LATEST_RELEASE)\\nwget -q --continue https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip\\nunzip chromedriver_linux64.zip\\nchmod +x chromedriver\\nmv chromedriver /usr/bin/chromedriver\\n\\n# Install Selenium\\n!pip install selenium\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_shell_cell_magic\u001b[0;34m(args, cmd)\u001b[0m\n\u001b[1;32m    110\u001b[0m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparsed_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_errors\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36mcheck_returncode\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcheck_returncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m       raise subprocess.CalledProcessError(\n\u001b[0m\u001b[1;32m    138\u001b[0m           \u001b[0mreturncode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m       )\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command '# Install chromium and chromium-driver using apt\n# apt-get update\n# apt-get install chromium chromium-driver # original code\n\n# Suggested Change: Install chromium using wget\n# Debian no longer provides chromium in Buster or Bullseye\n# Proposed solution: https://gist.github.com/korakot/f908ecc86f265ea290f5c6a9c7524031\n!apt-get update  # Update package lists to ensure apt can find the necessary packages\n!apt-get install -y wget curl unzip # Install wget, curl, and unzip if they are not already present\n\nwget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\napt install ./google-chrome-stable_current_amd64.deb -y\n\n# Install chromedriver using wget\n# Proposed solution: https://stackoverflow.com/a/74827505\nCHROMEDRIVER_VERSION=$(curl -sS -o - https://chromedriver.storage.googleapis.com/LATEST_RELEASE)\nwget -q --continue https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip\nunzip chromedriver_linux64.zip\nchmod +x chromedriver\nmv chromedriver /usr/bin/chromedriver\n\n# Install Selenium\n!pip install selenium\n' returned non-zero exit status 127."
          ]
        }
      ],
      "source": [
        "# %%shell\n",
        "# # Ubuntu no longer distributes chromium-browser outside of snap\n",
        "# # Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# # Add Debian Buster repository\n",
        "# cat > /etc/apt/sources.list.d/debian.list << \"EOF\"\n",
        "# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "# deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "# EOF\n",
        "\n",
        "# # Add keys\n",
        "# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "# apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "# # Export keys to keyrings\n",
        "# apt-key export 77E11517 | gpg --dearmor -o /usr/share/keyrings/debian-buster.gpg\n",
        "# apt-key export 22F3D138 | gpg --dearmor -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "# apt-key export E562B32A | gpg --dearmor -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# # Prefer Debian repository for chromium* packages only\n",
        "# # Note the double-blank lines between entries\n",
        "# cat > /etc/apt/preferences.d/chromium.pref << \"EOF\"\n",
        "# Package: *\n",
        "# Pin: release a=eoan\n",
        "# Pin-Priority: 500\n",
        "\n",
        "\n",
        "# Package: *\n",
        "# Pin: origin \"deb.debian.org\"\n",
        "# Pin-Priority: 300\n",
        "\n",
        "\n",
        "# Package: chromium*\n",
        "# Pin: origin \"deb.debian.org\"\n",
        "# Pin-Priority: 700\n",
        "# EOF\n",
        "\n",
        "# # Install chromium and chromium-driver\n",
        "# !apt-get update\n",
        "# !apt-get install chromium chromium-driver\n",
        "\n",
        "# # Install Selenium\n",
        "# !pip install selenium\n",
        "\n",
        "%%shell\n",
        "# Install chromium and chromium-driver using apt\n",
        "# apt-get update\n",
        "# apt-get install chromium chromium-driver # original code\n",
        "\n",
        "# Suggested Change: Install chromium using wget\n",
        "# Debian no longer provides chromium in Buster or Bullseye\n",
        "# Proposed solution: https://gist.github.com/korakot/f908ecc86f265ea290f5c6a9c7524031\n",
        "!apt-get update  # Update package lists to ensure apt can find the necessary packages\n",
        "!apt-get install -y wget curl unzip # Install wget, curl, and unzip if they are not already present\n",
        "\n",
        "wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "apt install ./google-chrome-stable_current_amd64.deb -y\n",
        "\n",
        "# Install chromedriver using wget\n",
        "# Proposed solution: https://stackoverflow.com/a/74827505\n",
        "CHROMEDRIVER_VERSION=$(curl -sS -o - https://chromedriver.storage.googleapis.com/LATEST_RELEASE)\n",
        "wget -q --continue https://chromedriver.storage.googleapis.com/${CHROMEDRIVER_VERSION}/chromedriver_linux64.zip\n",
        "unzip chromedriver_linux64.zip\n",
        "chmod +x chromedriver\n",
        "mv chromedriver /usr/bin/chromedriver\n",
        "\n",
        "# Install Selenium\n",
        "!pip install selenium"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "\n",
        "from tqdm import tqdm\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC"
      ],
      "metadata": {
        "id": "sWlBt3har_8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "WEBDRIVER_DELAY_TIME_INT = 10\n",
        "TIMEOUT_INT = 10\n",
        "\n",
        "# Initialize the Chrome WebDriver Service\n",
        "service = Service(executable_path=r\"/usr/bin/chromedriver\")\n",
        "\n",
        "# Set Chrome options\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument(\"--headless\")  # Run in headless mode (no GUI)\n",
        "chrome_options.add_argument(\"--no-sandbox\")\n",
        "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "chrome_options.add_argument(\"window-size=1920x1080\")\n",
        "chrome_options.headless = True\n",
        "\n",
        "# Initialize the WebDriver\n",
        "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "driver.implicitly_wait(TIMEOUT_INT)  # Set implicit wait time\n",
        "\n",
        "# Initialize explicit wait\n",
        "wait = WebDriverWait(driver, WEBDRIVER_DELAY_TIME_INT)"
      ],
      "metadata": {
        "id": "mB3mptOSr_5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_audio_links_from_menu(menu_url, driver):\n",
        "    # Navigate to the menu URL\n",
        "    driver.get(menu_url)\n",
        "\n",
        "    # Locate the container holding the play items\n",
        "    container = wait.until(EC.presence_of_element_located(\n",
        "        (By.CSS_SELECTOR, \"div.w-full.flex.flex-col.gap-3.pt-3\")\n",
        "    ))\n",
        "\n",
        "    # Find all play items within the container\n",
        "    play_items = container.find_elements(By.CSS_SELECTOR, \"div.play-item\")\n",
        "\n",
        "    # Extract links from the play items\n",
        "    links = []\n",
        "    for item in play_items:\n",
        "        try:\n",
        "            a_tag = item.find_element(By.CSS_SELECTOR, \".ptxt-track a\")\n",
        "            link = a_tag.get_attribute(\"href\")\n",
        "            links.append(link)\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    return links"
      ],
      "metadata": {
        "id": "g0faQPXIr_2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_audio_file(file_url, filepath):\n",
        "    # Send a GET request to download the file\n",
        "    response = requests.get(file_url, stream=True)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        # Write the file content in chunks to avoid memory issues\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            for chunk in response.iter_content(chunk_size=8192):\n",
        "                f.write(chunk)\n",
        "    else:\n",
        "        # Handle errors if the file cannot be downloaded\n",
        "        print(f\"Error downloading file from {file_url}; status: {response.status_code}\")"
      ],
      "metadata": {
        "id": "YsyW1Nznr_zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_track_info(driver):\n",
        "    # Extract track information from the page\n",
        "    audio_div = WebDriverWait(driver, 15).until(\n",
        "        EC.presence_of_element_located((By.CSS_SELECTOR, \"div[data-track-info]\"))\n",
        "    )\n",
        "    return json.loads(audio_div.get_attribute(\"data-track-info\"))\n",
        "\n",
        "def extract_genres(driver):\n",
        "    # Extract genres from the page\n",
        "    try:\n",
        "        genre_elem = driver.find_element(By.CSS_SELECTOR, \"span.md\\\\:col-span-6.flex.flex-wrap.gap-3\")\n",
        "        return [a.text.strip() for a in genre_elem.find_elements(By.TAG_NAME, \"a\") if a.text.strip()]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def extract_duration(driver):\n",
        "    # Extract the duration of the track\n",
        "    try:\n",
        "        duration_elem = driver.find_element(By.CSS_SELECTOR,\n",
        "                                            \"span.w-12.ml-auto.md\\\\:ml-0.col-span-2.inline-flex.justify-end.items-center\")\n",
        "        return duration_elem.text.strip()\n",
        "    except Exception:\n",
        "        return \"\""
      ],
      "metadata": {
        "id": "4_Tar7Gtr_w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_extra_info(driver):\n",
        "    # Extract additional information like 'Instrumental' and 'AI generated?'\n",
        "    instrumental = \"No\"\n",
        "    ai_generated = \"No\"\n",
        "    try:\n",
        "        info_container = driver.find_element(By.CSS_SELECTOR,\n",
        "                                             \"div.px-8.py-2.bg-gray-light.flex.flex-col.divide-y.divide-gray\")\n",
        "        info_divs = info_container.find_elements(By.CSS_SELECTOR,\n",
        "                                                 \"div.grid.grid-cols-1.md\\\\:grid-cons-8.py-6\")\n",
        "        for div in info_divs:\n",
        "            label = div.find_element(By.CSS_SELECTOR, \"span.font-\\\n",
        "\n",
        "\\[500\\\\]\n",
        "\n",
        ".md\\\\:col-span-2\").text.strip()\n",
        "            value = div.find_element(By.CSS_SELECTOR, \"span.md\\\\:col-span-6\").text.strip()\n",
        "            if \"Instrumental\" in label:\n",
        "                instrumental = value\n",
        "            if \"AI generated?\" in label:\n",
        "                ai_generated = value\n",
        "    except Exception:\n",
        "        pass\n",
        "    return instrumental, ai_generated"
      ],
      "metadata": {
        "id": "DiHFzHyCuVsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_page(audio_url, driver, index):\n",
        "    # Process individual audio page and save metadata\n",
        "    driver.get(audio_url)\n",
        "\n",
        "    track_info = extract_track_info(driver)\n",
        "    file_url = track_info.get(\"fileUrl\", \"\")\n",
        "    audio_name = track_info.get(\"title\", \"\").strip()\n",
        "    author = track_info.get(\"artistName\", \"\").strip()\n",
        "    genres = extract_genres(driver)\n",
        "    duration = extract_duration(driver)\n",
        "    instrumental, ai_generated = extract_extra_info(driver)\n",
        "\n",
        "    metadata = {\n",
        "        \"audioName\": audio_name,\n",
        "        \"author\": author,\n",
        "        \"genres\": genres,\n",
        "        \"instrumental\": instrumental,\n",
        "        \"ai_generated\": ai_generated,\n",
        "        \"duration\": duration,\n",
        "        \"audio_url\": audio_url\n",
        "    }\n",
        "\n",
        "    audio_filename = f\"audio_{index:04d}.mp3\"\n",
        "    meta_filename = f\"audio_{index:04d}.json\"\n",
        "    audio_filepath = os.path.join(\"crawled_data\", \"audio\", audio_filename)\n",
        "    meta_filepath = os.path.join(\"crawled_data\", meta_filename)\n",
        "\n",
        "    download_audio_file(file_url, audio_filepath)\n",
        "    with open(meta_filepath, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(metadata, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "    return metadata"
      ],
      "metadata": {
        "id": "CWXCr6RnuTWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loop_over_menu_pages(base_url, total_pages, driver):\n",
        "    all_links = []\n",
        "\n",
        "    for page in tqdm(range(1, total_pages + 1), desc=\"Extracting Links\", unit=\"page\"):\n",
        "        page_url = f\"{base_url}?page={page}\"\n",
        "        try:\n",
        "            # Extract links from the current page and add to the list\n",
        "            links = extract_audio_links_from_menu(page_url, driver)\n",
        "            all_links.extend(links)\n",
        "        except Exception as e:\n",
        "            # Handle errors gracefully\n",
        "            print(f\"Error on page {page}: {e}\")\n",
        "\n",
        "    return all_links"
      ],
      "metadata": {
        "id": "2DF8sLafr_uR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create necessary directories\n",
        "os.makedirs(\"crawled_data\", exist_ok=True)\n",
        "os.makedirs(os.path.join(\"crawled_data\", \"audio\"), exist_ok=True)\n",
        "\n",
        "# Define base URL and parameters\n",
        "base_url = \"https://freemusicarchive.org/genre/piano/\"\n",
        "total_pages = 10\n",
        "sample_idx = 1\n",
        "\n",
        "# Extract audio links from menu pages\n",
        "audio_links = loop_over_menu_pages(base_url, total_pages, driver)\n",
        "print(f\"Total audio links extracted: {len(audio_links)}\")\n",
        "\n",
        "# Download audio and metadata\n",
        "for audio_url in tqdm(audio_links, desc=\"Downloading Audio and Metadata\", unit=\"audio\"):\n",
        "    try:\n",
        "        process_audio_page(audio_url, driver, sample_idx)\n",
        "        sample_idx += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Error at: {audio_url} - {e}\")\n",
        "        continue\n",
        "    time.sleep(0.5)\n",
        "\n",
        "# Close the WebDriver\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "KHaUhT8-r_rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba==0.61.0 torchaudio==2.6.0 librosa==0.10.2.post1"
      ],
      "metadata": {
        "id": "kQltCVzAr_pN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchaudio\n",
        "import torchaudio.transforms as T\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from IPython.display import Audio\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "cD5Sl72qr_m8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the file using gdown\n",
        "!gdown 1u2WzsWUlyZbbPDfXAWXuLRMTwFkT21wa\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip -q crawled_piano_audio_40_pages.zip -d piano_audio_files_40_pages\n",
        "\n",
        "# Remove the zip file after extraction\n",
        "os.remove(\"crawled_piano_audio_40_pages.zip\")"
      ],
      "metadata": {
        "id": "zio1Rdu6r_kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_get_genres(json_path):\n",
        "    # Load JSON and extract genres\n",
        "    with open(json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "    return data.get('genres', [])\n",
        "\n",
        "def load_and_resample_audio(file_path, target_sr=22050):\n",
        "    # Load and resample audio to the target sample rate\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    if sr != target_sr:\n",
        "        audio = librosa.resample(audio, orig_sr=sr, target_sr=target_sr)\n",
        "    return audio, target_sr\n",
        "\n",
        "def audio_to_melspec(audio, sr, n_mels, n_fft=2048, hop_length=512, to_db=False):\n",
        "    # Convert audio to Mel Spectrogram\n",
        "    spec = librosa.feature.melspectrogram(\n",
        "        y=audio,\n",
        "        sr=sr,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        win_length=None,\n",
        "        window=\"hann\",\n",
        "        center=True,\n",
        "        pad_mode=\"reflect\",\n",
        "        power=2.0,\n",
        "        n_mels=n_mels\n",
        "    )\n",
        "    if to_db:\n",
        "        spec = librosa.power_to_db(spec, ref=np.max)\n",
        "    return spec\n",
        "\n",
        "def normalize_melspec(melspec, norm_range=(0, 1)):\n",
        "    # Normalize Mel Spectrogram\n",
        "    scaler = MinMaxScaler(feature_range=norm_range)\n",
        "    melspec = melspec.T\n",
        "    melspec_normalized = scaler.fit_transform(melspec)\n",
        "    return melspec_normalized.T\n",
        "\n",
        "def denormalize_melspec(melspec_normalized, original_melspec, norm_range=(0, 1)):\n",
        "    # Denormalize Mel Spectrogram\n",
        "    scaler = MinMaxScaler(feature_range=norm_range)\n",
        "    melspec = original_melspec.T\n",
        "    scaler.fit(melspec)\n",
        "    melspec_denormalized = scaler.inverse_transform(melspec_normalized.T)\n",
        "    return melspec_denormalized.T\n",
        "\n",
        "def melspec_to_audio(melspec, sr, n_fft=2048, hop_length=512, n_iter=64):\n",
        "    # Convert Mel Spectrogram back to audio\n",
        "    if np.any(melspec < 0):\n",
        "        melspec = librosa.db_to_power(melspec)\n",
        "    audio_reconstructed = librosa.feature.inverse.mel_to_audio(\n",
        "        melspec,\n",
        "        sr=sr,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        win_length=None,\n",
        "        window=\"hann\",\n",
        "        center=True,\n",
        "        pad_mode=\"reflect\",\n",
        "        power=2.0,\n",
        "        n_iter=n_iter\n",
        "    )\n",
        "    return audio_reconstructed\n",
        "\n",
        "def display_audio_files(reconstructed_audio, sr, title=\"\", original_audio=None):\n",
        "    # Display audio files\n",
        "    if original_audio is not None:\n",
        "        print(\"Original Audio:\")\n",
        "        ipd.display(ipd.Audio(original_audio, rate=sr))\n",
        "        print(\"Reconstructed Audio (from Mel Spectrogram):\")\n",
        "    else:\n",
        "        print(title)\n",
        "    ipd.display(ipd.Audio(reconstructed_audio, rate=sr))\n",
        "\n",
        "def show_spectrogram(spectrogram, title=\"Mel-Spectrogram\", denormalize=False, is_numpy=False):\n",
        "    # Show Mel Spectrogram\n",
        "    if not is_numpy:\n",
        "        spectrogram = spectrogram.squeeze().cpu().numpy()\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    if denormalize:\n",
        "        plt.imshow(spectrogram, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
        "    else:\n",
        "        plt.imshow(spectrogram, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\", vmin=0, vmax=1)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Mel Frequency\")\n",
        "    plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "mz7J_b5Puv_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the directory containing JSON files\n",
        "json_dir = os.path.join(\"piano_audio_files\", \"crawled_data\")\n",
        "all_genres = []\n",
        "\n",
        "# Iterate through all JSON files in the directory\n",
        "for filename in os.listdir(json_dir):\n",
        "    if filename.endswith('.json'):\n",
        "        # Load genres from each JSON file\n",
        "        json_path = os.path.join(json_dir, filename)\n",
        "        genres = load_and_get_genres(json_path)\n",
        "        all_genres.extend(genres)\n",
        "\n",
        "# Extract unique genres and display results\n",
        "unique_genres = set(all_genres)\n",
        "max_genres = len(unique_genres)\n",
        "\n",
        "print(f\"Total unique genres: {max_genres}\")\n",
        "print(f\"Unique genres: {unique_genres}\")"
      ],
      "metadata": {
        "id": "yAIj8cBhuv8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map genres to indices and vice versa\n",
        "genres2idx = {genre: idx for idx, genre in enumerate(unique_genres)}\n",
        "idx2genres = {idx: genre for genre, idx in genres2idx.items()}\n",
        "\n",
        "# Tokenize genres into their corresponding indices\n",
        "def tokenize(genres):\n",
        "    return [genres2idx[genre] for genre in genres if genre in genres2idx]\n",
        "\n",
        "# Detokenize tokens back into their corresponding genres\n",
        "def detokenize_tolist(tokens):\n",
        "    return [idx2genres[token] for token in tokens if token in idx2genres]\n",
        "\n",
        "# One-hot encode the list of tokenized genres\n",
        "def onehot_encode(tokens, max_genres):\n",
        "    onehot = np.zeros(max_genres)\n",
        "    onehot[tokens] = 1\n",
        "    return onehot\n",
        "\n",
        "# Decode one-hot encoded data back into a list of genre indices\n",
        "def onehot_decode(onehot):\n",
        "    return [idx for idx, val in enumerate(onehot) if val == 1]"
      ],
      "metadata": {
        "id": "_QQMlZNeuv5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AudioDataset(Dataset):\n",
        "    def __init__(self, data_dir, json_dir, sample_rate, duration, n_mels, n_genres, testset_amount=10):\n",
        "        self.data_dir = data_dir\n",
        "        self.files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".mp3\")]\n",
        "        self.json_dir = json_dir\n",
        "        self.json_files = [os.path.join(json_dir, f) for f in os.listdir(json_dir) if f.endswith(\".json\")]\n",
        "        self.sample_rate = sample_rate\n",
        "        self.duration = duration\n",
        "        self.fixed_length = sample_rate * duration\n",
        "        self.n_genres = n_genres\n",
        "        self.n_mels = n_mels\n",
        "        audios = []\n",
        "\n",
        "        # Load audio files and their metadata\n",
        "        for file_path, json_file_path in tqdm(zip(self.files, self.json_files),\n",
        "                                              desc=f\"Loading audio files in {data_dir}\",\n",
        "                                              unit=\"file\", total=len(self.files)):\n",
        "            audio, sr = load_and_resample_audio(file_path, target_sr=sample_rate)\n",
        "            genres_list = load_and_get_genres(json_file_path)\n",
        "            genres_tokens = tokenize(genres_list)\n",
        "            genres_input = onehot_encode(genres_tokens, n_genres)\n",
        "            genres_input = torch.tensor(genres_input, dtype=torch.long).unsqueeze(0)\n",
        "\n",
        "            n_samples = len(audio)\n",
        "            n_segments = n_samples // self.fixed_length\n",
        "\n",
        "            for i in range(n_segments):\n",
        "                start = i * self.fixed_length\n",
        "                end = (i + 1) * self.fixed_length\n",
        "                segment = audio[start:end]\n",
        "                mel_spec = audio_to_melspec(segment, sr, self.n_mels, to_db=True)\n",
        "                mel_spec_norm = normalize_melspec(mel_spec)\n",
        "                mel_spec = torch.tensor(mel_spec, dtype=torch.float32).unsqueeze(0)\n",
        "                mel_spec_norm = torch.tensor(mel_spec_norm, dtype=torch.float32).unsqueeze(0)\n",
        "                audios.append((mel_spec_norm, genres_input, mel_spec))\n",
        "\n",
        "        # Split the dataset into training and test sets\n",
        "        self.audios = audios[:len(audios) - testset_amount]\n",
        "        self.testset = audios[len(audios) - testset_amount:]\n",
        "\n",
        "        print(f\"Loaded {len(self.audios)} audio segments from {len(self.files)} files, \"\n",
        "              f\"each with shape: {self.audios[0][0].shape}, {self.audios[0][1].shape}, \"\n",
        "              f\"duration: {duration} seconds\")\n",
        "        print(f\"Test set: {len(self.testset)} audio segments\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audios)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        mel_spec_part, genres_input, mel_spec = self.audios[idx]\n",
        "        return mel_spec_part, genres_input, mel_spec"
      ],
      "metadata": {
        "id": "Tcy2iN3Uuv2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "sample_rate = 22050\n",
        "duration = 3  # Duration of audio segments in seconds\n",
        "n_mels = 256  # Number of Mel spectrogram bins\n",
        "batch_size = 128\n",
        "\n",
        "# Define directories\n",
        "audio_dir = os.path.join(\"piano_audio_files\", \"crawled_data\", \"audio\")\n",
        "json_dir = os.path.join(\"piano_audio_files\", \"crawled_data\")\n",
        "\n",
        "# Amount of test data\n",
        "testset_amount = 32\n",
        "\n",
        "# Load the dataset\n",
        "trainset = AudioDataset(audio_dir, json_dir, sample_rate, duration, n_mels, max_genres, testset_amount=testset_amount)\n",
        "testset = trainset.testset\n",
        "\n",
        "# Check if training data exists\n",
        "if len(trainset) == 0:\n",
        "    raise ValueError(f\"No .wav file found in {audio_dir}.\")\n",
        "\n",
        "# Create DataLoaders for training and testing\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "testloader = DataLoader(testset, batch_size=testset_amount, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "UBRNCCF7uvvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CVAE(nn.Module):\n",
        "    def __init__(self, d_model, latent_dim, n_frames, n_mels, n_genres):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.latent_dim = latent_dim\n",
        "        self.n_frames = int(np.ceil(n_frames / 2**3))\n",
        "        self.n_mels = int(np.ceil(n_mels / 2**3))\n",
        "        self.n_genres = n_genres\n",
        "\n",
        "        print(self.n_frames, self.n_mels)\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(1 + self.n_genres, d_model, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(d_model),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(0.05),\n",
        "\n",
        "            nn.Conv2d(d_model, d_model * 2, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(d_model * 2),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            nn.Conv2d(d_model * 2, d_model * 4, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(d_model * 4),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(0.15),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten()\n",
        "        )\n",
        "\n",
        "        # Latent space\n",
        "        self.fc_mu = nn.Linear(d_model * 4, latent_dim)\n",
        "        self.fc_logvar = nn.Linear(d_model * 4, latent_dim)\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder_input = nn.Linear(latent_dim + self.n_genres, d_model * 4 * self.n_frames * self.n_mels)\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(d_model * 4, d_model * 2, kernel_size=3, stride=2, padding=1, output_padding=(1, 0)),\n",
        "            nn.BatchNorm2d(d_model * 2),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(0.1),\n",
        "\n",
        "            nn.ConvTranspose2d(d_model * 2, d_model, kernel_size=3, stride=2, padding=1, output_padding=(1, 0)),\n",
        "            nn.BatchNorm2d(d_model),\n",
        "            nn.SiLU(),\n",
        "            nn.Dropout2d(0.05),\n",
        "\n",
        "            nn.ConvTranspose2d(d_model, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def forward(self, x, genres_input):\n",
        "        ori_genres_embed = genres_input.view(genres_input.size(0), -1)\n",
        "        genres_embed = ori_genres_embed.unsqueeze(-1).unsqueeze(-1)\n",
        "        genres_embed = genres_embed.expand(-1, -1, x.size(2), x.size(3))\n",
        "        x_genres = torch.cat((x, genres_embed), dim=1)\n",
        "\n",
        "        h = x_genres\n",
        "        shortcuts = []\n",
        "        for block in self.encoder:\n",
        "            h = block(h)\n",
        "            if isinstance(block, nn.SiLU):\n",
        "                shortcuts.append(h)\n",
        "\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        z_genres = torch.cat((z, ori_genres_embed), dim=1)\n",
        "\n",
        "        h_dec = self.decoder_input(z_genres)\n",
        "        h_dec = h_dec.view(-1, self.d_model * 4, self.n_frames, self.n_mels)\n",
        "\n",
        "        for block in self.decoder:\n",
        "            if isinstance(block, nn.ConvTranspose2d) and shortcuts:\n",
        "                shortcut = shortcuts.pop()\n",
        "                h_dec = h_dec + shortcut\n",
        "            h_dec = block(h_dec)\n",
        "\n",
        "        recon = h_dec[:, :, :x.size(2), :x.size(3)]\n",
        "        return recon, mu, logvar"
      ],
      "metadata": {
        "id": "3mBUiz8IvlUJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    # Calculate reconstruction loss\n",
        "    recon_loss = nn.functional.mse_loss(recon_x, x, reduction=\"sum\")\n",
        "\n",
        "    # Calculate KL divergence\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    # Return the total loss\n",
        "    return recon_loss + KLD\n",
        "\n",
        "\n",
        "def train_vae(model, dataloader, optimizer, scheduler, num_epochs, verbose_interval=50):\n",
        "    model.train()  # Set the model to training mode\n",
        "    losses = []\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs), desc=\"Training\", unit=\"epoch\"):\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_idx, (data, genres_input, ori_data) in enumerate(dataloader):\n",
        "            data = data.to(device)\n",
        "            genres_input = genres_input.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            recon, mu, logvar = model(data, genres_input)\n",
        "\n",
        "            # Compute loss and backpropagate\n",
        "            loss = loss_function(recon, data, mu, logvar)\n",
        "            loss.backward()\n",
        "            train_loss += loss.item()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Update the learning rate scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "        # Compute average loss for the epoch\n",
        "        avg_loss = train_loss / len(dataloader.dataset)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Print epoch summary\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {avg_loss:.4f}, \"\n",
        "              f\"Lr: {scheduler.get_last_lr()[0]}\")\n",
        "\n",
        "        # Visualize spectrograms at specified intervals\n",
        "        if epoch == 0 or (epoch + 1) % verbose_interval == 0:\n",
        "            data = data[0].detach().cpu()\n",
        "            recon_img = recon[0].detach().cpu()\n",
        "            show_spectrogram(data, title=\"Original Spectrogram\")\n",
        "            show_spectrogram(recon_img, title=\"Reconstructed Spectrogram\")\n",
        "\n",
        "    return mu, logvar, losses"
      ],
      "metadata": {
        "id": "3q5GCA6dvlRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define parameters\n",
        "d_model = 64\n",
        "latent_dim = 128\n",
        "lr = 2e-4\n",
        "num_epochs = 100\n",
        "step_size = num_epochs // 2\n",
        "verbose_interval = num_epochs // 10\n",
        "gamma = 0.5\n",
        "\n",
        "# Initialize the CVAE model\n",
        "model = CVAE(d_model, latent_dim, n_mels, frame, max_genres).to(device)\n",
        "\n",
        "# Define optimizer and learning rate scheduler\n",
        "optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "# Print total number of parameters in the model\n",
        "print(f\"Total number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
        "\n",
        "# Train the model\n",
        "mu, logvar, losses = train_vae(model, trainloader, optimizer, scheduler, num_epochs, verbose_interval=verbose_interval)"
      ],
      "metadata": {
        "id": "z3SQVI0CvlOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, dataloader, genres_list, num_samples=5, diff_level=1):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Get a batch of data from the dataloader\n",
        "        data, old_genres_input, ori_data = next(iter(dataloader))\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Prepare genres input\n",
        "        genres_tokens = tokenize(genres_list)\n",
        "        genres_input = onehot_encode(genres_tokens, model.n_genres)\n",
        "        genres_input = torch.tensor(genres_input, dtype=torch.long).unsqueeze(0)\n",
        "        genres_input = genres_input.repeat(old_genres_input.shape[0], 1)\n",
        "        genres_input = genres_input.to(device)\n",
        "\n",
        "        # Generate reconstructed data\n",
        "        recon, mu, logvar = model(data, genres_input)\n",
        "\n",
        "        ori_audios = []\n",
        "        recon_audios = []\n",
        "\n",
        "        for i in range(num_samples):\n",
        "            # Get genres for original data\n",
        "            old_genres_list = detokenize_tolist(onehot_decode(old_genres_input[i].squeeze().tolist()))\n",
        "\n",
        "            # Display spectrograms\n",
        "            show_spectrogram(data[i], title=\"Original Spectrogram with Genres: \" + \", \".join(old_genres_list))\n",
        "            show_spectrogram(recon[i], title=\"Reconstructed Spectrogram with Genres: \" + \", \".join(genres_list))\n",
        "\n",
        "            # Compute and display difference spectrogram\n",
        "            diff_spectrogram = torch.abs(data[i] - recon[i]) * diff_level\n",
        "            show_spectrogram(diff_spectrogram, title=f\"Difference Spectrogram (|Original - Reconstructed|) * {diff_level}\")\n",
        "\n",
        "            # Print loss\n",
        "            print(\"Loss: \", loss_function(recon[i], data[i], mu, logvar).item())\n",
        "\n",
        "            # Reconstruct audio from spectrogram\n",
        "            spec_denorm = denormalize_melspec(recon[i].cpu().numpy().squeeze(), ori_data[i].cpu().numpy().squeeze())\n",
        "            audio_reconstructed = melspec_to_audio(spec_denorm, sr=sample_rate)\n",
        "            ori_audio = melspec_to_audio(ori_data[i].cpu().numpy().squeeze(), sr=sample_rate)\n",
        "\n",
        "            # Store audio results\n",
        "            recon_audios.append(audio_reconstructed)\n",
        "            ori_audios.append(ori_audio)\n",
        "\n",
        "            # Display audio files\n",
        "            display_audio_files(ori_audio, sample_rate, title=\"Original Audio with Genres: \" + \", \".join(old_genres_list))\n",
        "            display_audio_files(audio_reconstructed, sample_rate, title=\"Reconstructed Audio with Genres: \" + \", \".join(genres_list))\n",
        "\n",
        "        # Concatenate audio samples if num_samples > 1\n",
        "        if num_samples > 1:\n",
        "            print(\"-\" * 100, \"Connect all audio\", \"-\" * 100)\n",
        "            recon_ori_audios = np.concatenate(ori_audios)\n",
        "            display_audio_files(recon_ori_audios, sample_rate, title=\"Connect all original audio\")\n",
        "            recon_audios = np.concatenate(recon_audios)\n",
        "            display_audio_files(recon_audios, sample_rate, title=\"Connect all reconstructed audio\")"
      ],
      "metadata": {
        "id": "q2sbpAhiw36z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}